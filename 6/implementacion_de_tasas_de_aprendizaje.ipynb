{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "implementacion_de_tasas_de_aprendizaje.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "vctIaW7u8FYa"
      },
      "source": [
        "Implementación de tasas de aprendizaje\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bdC7vEy8FYc",
        "outputId": "631862b0-36c1-452d-80af-c1eb1f7b43f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Implemente el algorithmo de escalado inverso de la tasa de\n",
        "# aprendizaje e imprima los resultados para las primeras 10 \n",
        "# iteraciones\n",
        "#\n",
        "# Rta/\n",
        "# 0.5000, 3.0000\n",
        "# -0.1839, 2.4920\n",
        "# 0.1384, 2.5796\n",
        "# 0.1824, 2.5579\n",
        "# 0.2033, 2.5376\n",
        "# 0.2168, 2.5208\n",
        "# 0.2265, 2.5068\n",
        "# 0.2342, 2.4950\n",
        "# 0.2405, 2.4847\n",
        "# 0.2458, 2.4757\n",
        "# 0.2503, 2.4678\n",
        "#\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def SSE(w0, w1):\n",
        "    return sum([(v - w0 - w1 * u) ** 2 for u, v in zip(x, d)])\n",
        "\n",
        "\n",
        "def gSSE(w0, w1):\n",
        "    e = [(v - w0 - w1 * u) for u, v in zip(x, d)]\n",
        "    gw0 = -2 * sum(e)\n",
        "    gw1 = -2 * sum([q * v for q, v in zip(e, x)])\n",
        "    return (gw0, gw1)\n",
        "\n",
        "\n",
        "\n",
        "def mejora(w0, w1, mu):\n",
        "    #\n",
        "    # Computo del gradiente para los parámetros actuales\n",
        "    #\n",
        "    gw0, gw1 = gSSE(w0, w1)\n",
        "\n",
        "    #\n",
        "    # Corrección de los parámetros\n",
        "    #\n",
        "    w0 = w0 - mu * gw0\n",
        "    w1 = w1 - mu * gw1\n",
        "\n",
        "    #\n",
        "    #  Parámetros corregidos\n",
        "    #\n",
        "    return w0, w1\n",
        "\n",
        "x = [\n",
        "    0.1087,  0.2698,  0.3765,  0.2146,  0.9155,  \n",
        "    0.0246,  0.0221,  0.8632,  0.6460,  0.2092,  \n",
        "    0.8567,  0.1591,  0.9647,  0.6231,  0.7460,  \n",
        "    0.3654,  0.3065,  0.6886,  0.4966,  0.2008,  \n",
        "    0.2618,  0.7607,  0.1563,  0.4424,  0.7731\n",
        "]\n",
        "\n",
        "d = [\n",
        "    0.9519,  1.1237,  1.2360,  1.0526,  2.0743,\n",
        "    0.7906,  0.7603,  2.0533,  1.6887,  1.0563,\n",
        "    2.0991,  0.8953,  2.1917,  1.6266,  1.8508,\n",
        "    1.2828,  1.2283,  1.8722,  1.4657,  1.0418,\n",
        "    1.1097,  1.7826,  0.9711,  1.4267,  1.8248\n",
        "]\n",
        "\n",
        "# Parámetros del escalado inverso\n",
        "mu0 = 0.03\n",
        "n = 1.1\n",
        "\n",
        "w0 = 0.5\n",
        "w1 = 3.0\n",
        "for epoch in range(10):\n",
        "    print('{:0.4f}, {:0.4f}'.format(w0, w1))\n",
        "    mu = mu0 / (epoch + 1) ** n\n",
        "    w0, w1 = mejora(w0, w1, mu)\n",
        "    \n",
        "    \n",
        "    \n",
        "# ---->>> Evaluación ---->>>\n",
        "print('{:0.4f}, {:0.4f}'.format(w0, w1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5000, 3.0000\n",
            "-0.1839, 2.4920\n",
            "0.1384, 2.5796\n",
            "0.1824, 2.5579\n",
            "0.2033, 2.5376\n",
            "0.2168, 2.5208\n",
            "0.2265, 2.5068\n",
            "0.2342, 2.4950\n",
            "0.2405, 2.4847\n",
            "0.2458, 2.4757\n",
            "0.2503, 2.4678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BFoCC0g8FYd",
        "outputId": "0a788c66-c93e-4417-9409-2da04063860f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Implemente el algorithmo de estrategia óptima de la tasa de\n",
        "# aprendizaje e imprima los resultados para las primeras 10 \n",
        "# iteraciones\n",
        "#\n",
        "# Rta/\n",
        "# 0.5000, 3.0000\n",
        "# 0.4430, 2.9577\n",
        "# 0.3956, 2.9202\n",
        "# 0.3562, 2.8868\n",
        "# 0.3237, 2.8569\n",
        "# 0.2969, 2.8300\n",
        "# 0.2750, 2.8056\n",
        "# 0.2573, 2.7833\n",
        "# 0.2431, 2.7629\n",
        "# 0.2318, 2.7441\n",
        "# 0.2230, 2.7266\n",
        "#\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def SSE(w0, w1):\n",
        "    return sum([(v - w0 - w1 * u) ** 2 for u, v in zip(x, d)])\n",
        "\n",
        "\n",
        "def gSSE(w0, w1):\n",
        "    e = [(v - w0 - w1 * u) for u, v in zip(x, d)]\n",
        "    gw0 = -2 * sum(e)\n",
        "    gw1 = -2 * sum([q * v for q, v in zip(e, x)])\n",
        "    return (gw0, gw1)\n",
        "\n",
        "\n",
        "def mejora(w0, w1, mu):\n",
        "    #\n",
        "    # Computo del gradiente para los parámetros actuales\n",
        "    #\n",
        "    gw0, gw1 = gSSE(w0, w1)\n",
        "\n",
        "    #\n",
        "    # Corrección de los parámetros\n",
        "    #\n",
        "    w0 = w0 - mu * gw0\n",
        "    w1 = w1 - mu * gw1\n",
        "\n",
        "    #\n",
        "    #  Parámetros corregidos\n",
        "    #\n",
        "    return w0, w1\n",
        "\n",
        "x = [\n",
        "    0.1087,  0.2698,  0.3765,  0.2146,  0.9155,  \n",
        "    0.0246,  0.0221,  0.8632,  0.6460,  0.2092,  \n",
        "    0.8567,  0.1591,  0.9647,  0.6231,  0.7460,  \n",
        "    0.3654,  0.3065,  0.6886,  0.4966,  0.2008,  \n",
        "    0.2618,  0.7607,  0.1563,  0.4424,  0.7731\n",
        "]\n",
        "\n",
        "d = [\n",
        "    0.9519,  1.1237,  1.2360,  1.0526,  2.0743,\n",
        "    0.7906,  0.7603,  2.0533,  1.6887,  1.0563,\n",
        "    2.0991,  0.8953,  2.1917,  1.6266,  1.8508,\n",
        "    1.2828,  1.2283,  1.8722,  1.4657,  1.0418,\n",
        "    1.1097,  1.7826,  0.9711,  1.4267,  1.8248\n",
        "]\n",
        "\n",
        "# Parámetros del algoritmo\n",
        "mu0 = 0.05\n",
        "alpha = 0.001\n",
        "\n",
        "t0 = 1 / (alpha * mu0)\n",
        "\n",
        "w0 = 0.5\n",
        "w1 = 3.0\n",
        "for epoch in range(10):\n",
        "    print('{:0.4f}, {:0.4f}'.format(w0, w1))\n",
        "    mu = mu0 / (alpha * ((epoch + 1) + t0))\n",
        "    w0, w1 = mejora(w0, w1, mu)\n",
        "    \n",
        "# ---->>> Evaluación ---->>>    \n",
        "print('{:0.4f}, {:0.4f}'.format(w0, w1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5000, 3.0000\n",
            "0.4430, 2.9577\n",
            "0.3956, 2.9202\n",
            "0.3562, 2.8868\n",
            "0.3237, 2.8569\n",
            "0.2969, 2.8300\n",
            "0.2750, 2.8056\n",
            "0.2573, 2.7833\n",
            "0.2431, 2.7629\n",
            "0.2318, 2.7441\n",
            "0.2230, 2.7266\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}