{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"optimizacion_usando_ElasticNet.ipynb","provenance":[{"file_id":"https://github.com/jdvelasq/datalabs/blob/master/notebooks/ml_fundamentals/optimizacion_usando_ElasticNet.ipynb","timestamp":1630870335935}]}},"cells":[{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false,"id":"FtR2sLpjcLw9"},"source":["Optimización usando ElasticNet\n","==="]},{"cell_type":"markdown","metadata":{"id":"f7J-drymcLxB"},"source":["En esta técnica se combina la penalización de ridge regression y LASSO, tal como se indica en la siguiente ecuación:"]},{"cell_type":"markdown","metadata":{"id":"XyHJNz_PcLxC"},"source":["$$ \\sum_{i=1}^N (y_i - g(x_i))^2 + \\alpha \\rho * (\\sum_{p=1} |w_p|) + \\frac{\\alpha (1 - \\rho)}{2}(\\sum_{p=1} w_p^2)$$"]},{"cell_type":"markdown","metadata":{"id":"L_pe1HYHcLxC"},"source":["$\\alpha$ y $\\rho$ son hiperparámetros suministrados por el usuario. **Nota:** Para el modelo lineal, la penalización solo aplica para los coeficientes de $x$, no para el intercepto."]},{"cell_type":"code","metadata":{"id":"Yhn8_P1ncLxD","executionInfo":{"status":"ok","timestamp":1630940563466,"user_tz":300,"elapsed":241,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}}},"source":["#\n","# A continuación se presenta la implementación de un modelo de\n","# regresión lineal que usa la función de penalización ElasticNet \n","# para estimar los parámetros óptimos. Complete el código presentado\n","# para que pasen las pruebas definidas en las celdas restantes.\n","#\n","import numpy as np\n","import pandas as pd\n","import pytest\n","\n","\n","class ElasticNetRegression:\n","    def __init__(self, intercept, coef, maxiter, mu, alpha, rho):\n","        self.intercept_ = intercept\n","        self.coef_ = np.array(coef)\n","        self._maxiter = maxiter\n","        self._mu = mu\n","        self._alpha = alpha\n","        self._rho = rho\n","        self._grad_coef = np.array(coef)\n","        self._grad_intercept = intercept\n","\n","    def compute_loss(self, x, y):\n","        d = self.g(x)\n","        return  np.sum([(yi - di)**2 for yi, di in zip(y, d)]) + self._alpha * self._rho * np.sum([abs(wp) for wp in self.coef_]) + (self._alpha * (1 -  self._rho)) / 2 * np.sum([wp**2 for wp in self.coef_])\n","\n","    def g(self, x):\n","        return [self.coef_[0] * d[0] + self.coef_[1] * d[1] + self.intercept_ for d in x]\n","\n","    def predict(self, x):\n","        return self.g(x)\n","\n","    def compute_gradient(self, x, y):\n","        d = [self.coef_[0] * d[0] + self.coef_[1] * d[1] + self.intercept_ for d in x]\n","        e = [yi - di for yi, di in zip(y, d)]\n","\n","        self._grad_coef[0] = -2 * np.sum([ei * xi[0] for xi, ei in zip(x, e)]) + self._alpha * self._rho * np.where(self.coef_[0] > 0, 1, -1) + self._alpha * (1 - self._rho) * self.coef_[0]\n","        self._grad_coef[1] = -2 * np.sum([ei * xi[1] for xi, ei in zip(x, e)]) + self._alpha * self._rho * np.where(self.coef_[1] > 0, 1, -1) + self._alpha * (1 - self._rho) * self.coef_[1]\n","\n","        self._grad_intercept = - 2 * np.sum(e)\n","\n","    def fit(self, x, y):\n","        for iter in range(self._maxiter):\n","            self.compute_gradient(x, y)\n","            self.improve()\n","\n","    def improve(self):\n","        self.intercept_ = self.intercept_ - self._mu * self._grad_intercept\n","        self.coef_ = self.coef_ - self._mu * self._grad_coef\n","\n","\n","x = [\n","    [0.0, 0.1],\n","    [0.2, 0.3],\n","    [0.4, 0.5],\n","    [0.6, 0.7],\n","    [0.8, 0.9],\n","    [1.0, 1.1],\n","]\n","\n","# y = 1 x1 + 1.1 x2 + 0.2\n","y = [\n","    0.31,\n","    0.73,\n","    1.15,\n","    1.57,\n","    1.99,\n","    2.41,\n","]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-a1A0XEcLxF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630871535272,"user_tz":300,"elapsed":354,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"b8289630-d4e4-4894-d90a-b87ec896ff16"},"source":["#\n","# Test 1\n","# =============================================================================\n","# Implemente la función de pérdida.\n","#\n","# Rta/\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = ElasticNetRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=10,\n","    rho = 10,\n",")\n","pytest.approx(lr.compute_loss(x, y), 0.0001) == 51.7044"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"XXMB1z5XcLxH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630871558873,"user_tz":300,"elapsed":276,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"d137393c-fc3b-4529-e8ea-99393e83ac67"},"source":["#\n","# Test 2\n","# =============================================================================\n","# Implemente la función de pronóstico\n","#\n","# Rta/\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = ElasticNetRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=10,\n","    rho = 10,\n",")\n","all(\n","    pytest.approx(a) == b\n","    for a, b in zip(lr.predict(x), [0.13, 0.23, 0.33, 0.43, 0.53, 0.63])\n",")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"RtW_QIMfcLxI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630872314008,"user_tz":300,"elapsed":282,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"aad76d98-02a9-4fb9-9391-9247ab12e78e"},"source":["#\n","# Test 3\n","# =============================================================================\n","# Implemente el gradiente\n","#\n","# Rta/\n","# True\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = ElasticNetRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=10,\n","    rho = 10,\n",")\n","lr.compute_gradient(x, y)\n","print(lr._grad_intercept == pytest.approx(-11.76))\n","print(all(pytest.approx(a) == b for a, b in zip(lr._grad_coef, [73.88 , 63.704])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]},{"cell_type":"code","metadata":{"id":"to-0jgbYcLxJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630872318166,"user_tz":300,"elapsed":784,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"b44f86b5-f301-480c-9839-6ee1e4b90ff9"},"source":["#\n","# Test 4\n","# =============================================================================\n","# Implemente la función fit\n","#\n","# Rta/\n","# True\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = ElasticNetRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=10,\n","    rho = 10,\n",")\n","lr.fit(x, y)\n","print(pytest.approx(lr.intercept_, 0.001) == 1.391750)\n","print(all(pytest.approx(a, 0.001) == b for a, b in zip(lr.coef_, [0.010658, 0.057296])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]}]}