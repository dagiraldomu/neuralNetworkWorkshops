{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"optimizacion_usando_LASSO.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false,"id":"JAG1KxmPiCOv"},"source":["Optimización usando LASSO\n","==="]},{"cell_type":"markdown","metadata":{"id":"GZ7Yy0ydiCOy"},"source":["En esta técnica, el término de penalización es el valor absoluto de los coeficientes del modelo de regresión.\n","\n","$$ \\sum_{i=1}^N (y_i -  g(x_i))^2 + \\alpha \\sum_{p=1}^P ||w_p|| $$\n"]},{"cell_type":"markdown","metadata":{"id":"9okoMdy9iCOz"},"source":["$\\alpha$ es un hiperparámetro suministrado por el usuario. **Nota:** Para el modelo lineal, la penalización solo aplica para los coeficientes de $x$, no para el intercepto."]},{"cell_type":"code","metadata":{"id":"ymfD3aBgiCO0","executionInfo":{"status":"ok","timestamp":1630940503393,"user_tz":300,"elapsed":472,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}}},"source":["#\n","# A continuación se presenta la implementación de un modelo de\n","# regresión lineal que usa la función de penalización LASSO para\n","# estimar los parámetros óptimos. Complete el código presentado\n","# para que pasen las pruebas definidas en las celdas restantes.\n","#\n","import numpy as np\n","import pandas as pd\n","import pytest\n","\n","\n","class LassoRegression:\n","    def __init__(self, intercept, coef, maxiter, mu, alpha):\n","        self.intercept_ = intercept\n","        self.coef_ = np.array(coef)\n","        self._maxiter = maxiter\n","        self._mu = mu\n","        self._alpha = alpha\n","        self._grad_coef = np.array(coef)\n","        self._grad_intercept = intercept\n","\n","    def compute_loss(self, x, y):\n","        d = self.g(x)\n","        return  np.sum([(yi - di)**2 for yi, di in zip(y, d)]) + self._alpha * np.sum(self.coef_)\n","\n","    def g(self, x):\n","        return [self.coef_[0] * d[0] + self.coef_[1] * d[1] + self.intercept_ for d in x]\n","\n","    def predict(self, x):\n","        return self.g(x)\n","\n","    def compute_gradient(self, x, y):\n","        d = [self.coef_[0] * d[0] + self.coef_[1] * d[1] + self.intercept_ for d in x]\n","        e = [yi - di for yi, di in zip(y, d)]\n","\n","        self._grad_coef[0] = -2 * np.sum([ei * xi[0] for xi, ei in zip(x, e)]) + self._alpha * np.where(self.coef_[0] > 0, 1, -1)\n","        self._grad_coef[1] = -2 * np.sum([ei * xi[1] for xi, ei in zip(x, e)]) + self._alpha * np.where(self.coef_[1] > 0, 1, -1)\n","\n","        self._grad_intercept = - 2 * np.sum(e) \n","\n","    def fit(self, x, y):\n","        for iter in range(self._maxiter):\n","            self.compute_gradient(x, y)\n","            self.improve()\n","\n","    def improve(self):\n","        self.intercept_ = self.intercept_ - self._mu * self._grad_intercept\n","        self.coef_ = self.coef_ - self._mu * self._grad_coef\n","\n","\n","x = [\n","    [0.0, 0.1],\n","    [0.2, 0.3],\n","    [0.4, 0.5],\n","    [0.6, 0.7],\n","    [0.8, 0.9],\n","    [1.0, 1.1],\n","]\n","\n","# y = 1 x1 + 1.1 x2 + 0.2\n","\n","# (y - w0 x1 + w1 x2 + b)^2 + a * (|w0|+|w1|)\n","\n","y = [\n","    0.31,\n","    0.73,\n","    1.15,\n","    1.57,\n","    1.99,\n","    2.41,\n","]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOsHO1YjiCO2","executionInfo":{"status":"ok","timestamp":1630940512661,"user_tz":300,"elapsed":201,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"92fd7127-0be8-4d8c-ff6c-50af576b6490"},"source":["#\n","# Test 1\n","# =============================================================================\n","# Implemente la función de pérdida.\n","#\n","# Rta/\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = LassoRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=100,\n",")\n","\n","pytest.approx(lr.compute_loss(x, y), 0.0001) == 57.5544"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"oq3sarNLiCO2","executionInfo":{"status":"ok","timestamp":1630940515075,"user_tz":300,"elapsed":205,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"b28158de-c7c8-4aef-c187-603b60ff3d37","colab":{"base_uri":"https://localhost:8080/"}},"source":["#\n","# Test 2\n","# =============================================================================\n","# Implemente la función de pronóstico\n","#\n","# Rta/\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = LassoRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=100,\n",")\n","\n","all(\n","    pytest.approx(a) == b\n","    for a, b in zip(lr.predict(x), [0.13, 0.23, 0.33, 0.43, 0.53, 0.63])\n",")"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"bA8PuyFyiCO3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630940517924,"user_tz":300,"elapsed":257,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"accb3779-58b4-4147-ec7e-c8ae59473450"},"source":["#\n","# Test 3\n","# =============================================================================\n","# Implemente el gradiente\n","#\n","# Rta/\n","# True\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = LassoRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=10000,\n","    mu=0.001,\n","    alpha=100,\n",")\n","lr.compute_gradient(x, y)\n","\n","print(lr._grad_intercept == pytest.approx(-11.76))\n","print(all(pytest.approx(a) == b for a, b in zip(lr._grad_coef, [91.88 , 90.704])))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qj5WZYtpiCO4","executionInfo":{"status":"ok","timestamp":1630940520767,"user_tz":300,"elapsed":221,"user":{"displayName":"Daniel Giraldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmxJdPNe24-UnDgytbkBCMuLibvfMcrZOheC_=s64","userId":"03534606879637833942"}},"outputId":"272a4512-4822-4ca6-b4e0-f22c215c0ad5"},"source":["#\n","# Test 4\n","# =============================================================================\n","# Implemente la función fit\n","#\n","# Rta/\n","# True\n","# True\n","#\n","\n","# ---->>> Evaluación ---->>>\n","lr = LassoRegression(\n","    intercept=0.1,\n","    coef=[0.2, 0.3],\n","    maxiter=1000,\n","    mu=0.001,\n","    alpha=100,\n",")\n","lr.fit(x, y)\n","print(pytest.approx(lr.intercept_, 0.001) == 1.356084)\n","print(all(pytest.approx(a, 0.001) == b for a, b in zip(lr.coef_, [-0.045481 , -0.019872])))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n"]}]}]}